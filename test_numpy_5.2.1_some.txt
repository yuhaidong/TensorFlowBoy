1 损失函数：
	损失函数用来刻画预测值与真实值之间的差异，使用上有3种情况：
		1 分类问题：一般采用“交叉熵+softmax回归”，见P75；
		2 回归问题：一般采用“均方误差”，见P77；
		3 自定义损失函数：还可以自定义损失函数，见P78

2 反向传播算法
<<<<<<< HEAD
	反向传播算法要用到损失函数，反向传播算法就是通过损失函数刻画出的测试值与真实值之间的差异来对参数进行优化的。
=======
	反向传播算法是根据损失函数来优化神经网络中参数的取值。
>>>>>>> 5abce74e3ce918e07c7dd0f8827bfda1e7819e79
	梯度下降算法主要用于优化单个参数的取值，而反向传播算法给出了一个高效的方式在所有参数上使用梯度下降算法，从而使神经网络模型在训练数据上的损失函数尽可能小。
	反向传播算法会计算损失函数对每一个参数的梯度，再根据梯度和学习率使用梯度下降算法更新每一个参数，反向传播算法可以说是梯度下降在链式法则中的应用。

3 梯度下降算法
	梯度其实就是损失函数当前所在的位置，梯度下降算法，对参数的梯度通过求偏导的方式计算出来，再根据学习率来更新参数。

4 随机梯度下降